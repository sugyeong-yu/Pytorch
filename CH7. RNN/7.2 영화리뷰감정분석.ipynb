{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB데이터를 가지고 텍스트 감정분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB 는 50000건의 영화리뷰 (영어문장)으로 구성.\n",
    "#### 긍정적리뷰=2, 부정적리뷰=1 로 labeling\n",
    "\n",
    "- 목표 : 영화평의 전체 내용을 압축, 압축된 리뷰가 긍정적 부정적인지 파단해주는 분류모델을 만드는것\n",
    "1. 데이터로드\n",
    "2. 단어사전만들기\n",
    "3. 검증셋나누기\n",
    "4. 단어임베딩 \n",
    "5. 모델정의\n",
    "6. 학습 및 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 필요한 하이퍼파라미터 정의\n",
    "batch_size=64\n",
    "lr=0.001\n",
    "epochs=40\n",
    "use_cuda=torch.cuda.is_available()\n",
    "device=torch.device(\"cuda\" if use_cuda else \"cpu\") #gpu가있으면 gpu로 그렇지않으면 cpu로 환경설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchtext를 이용하면 정보가 담긴 TEXT와 LABEL이라는 객체를 쉽게 생성할 수 있다.\\\n",
    "torchtext.data.Field : 필드만 정의. 어떤전처리도 되지않은 상태\n",
    "- sequential파라미터 : 데이터셋이 순차적인 데이터셋인 것을 명시\n",
    "- batch_first : 신경망에 입력되는 텐서의 첫번째 차원값이  batch_size가 되도록\n",
    "- lower : 데이터속 모든 영문이 소문자가 되도록.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDB로딩\n",
    "text=data.Field(sequential=True, batch_first=True, lower=True) \n",
    "label= data.Field(sequential=False, batch_first=True) # label은 순서가 필요없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".data\\imdb\\aclImdb_v1.tar.gz: 100%|███████████████████████████████████████████████| 84.1M/84.1M [01:13<00:00, 1.14MB/s]\n"
     ]
    }
   ],
   "source": [
    "trainset, testset = datasets.IMDB.splits(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.datasets.imdb.IMDB'>\n",
      "<generator object Dataset.__getattr__ at 0x00000216FB0DB048>\n",
      "<torchtext.data.example.Example object at 0x00000216D57DC6A0>\n"
     ]
    }
   ],
   "source": [
    "print(type(trainset))\n",
    "print(trainset.shape)\n",
    "print(trainset.examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워드임베딩에 필요한 단어사전을 만듬  ( field.build_vocab(sample))\n",
    "text.build_vocab(trainset, min_freq=5) # 학습데이터에서, min_freq : 최소 n번 이상 등장한 단어만을 사전에 담겠다.\n",
    "label.build_vocab(trainset)\n",
    "# 생성된 단어집합 내의 단어들은 stoi를 통해 확인가능\n",
    "print(text.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IMDB에선 val set이 따로 존재하지 않기 때문에 train set을 쪼개어 validation set으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset=trainset.split(split_ratio=0.8)\n",
    "\n",
    "#비슷한 길이의 예제들을 묶어주는 반복자(iterator)를 정의. \n",
    "train_iter, val_iter, test_iter=data.BucketIterator.splits((trainset,valset,testset),batch_size=batch_size,shuffle=True, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(text.vocab) # 사전 속 단어의 개수\n",
    "n_classes=2 # 레이블의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[학습셋]: 20000 [검증셋]: 5000 [테스트셋]: 25000 [단어수]: 46159 [클래스] 2\n"
     ]
    }
   ],
   "source": [
    "print(\"[학습셋]: %d [검증셋]: %d [테스트셋]: %d [단어수]: %d [클래스] %d\"\n",
    "      % (len(trainset),len(valset), len(testset), vocab_size, n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN모델구현\n",
    "class BasicGRU(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
    "        # n_layers : 은닉벡터들의 층 수, 아주복잡한게 아닌이상 2 이하로..\n",
    "        super(BasicGRU,self).__init__()\n",
    "        print(\"Building Basic GRU model...\")\n",
    "        self.n_layers=n_layers\n",
    "        self.embed=nn.Embedding(n_vocab,embed_dim) # Embedding은 사전에 등재된 단어수, 임베딩된 단어텐서가 지니는 차원값\n",
    "        self.hidden_dim=hidden_dim #은닉벡터 개수\n",
    "        self.dropout=nn.Dropout(dropout_p)\n",
    "        self.gru=nn.GRU(embed_dim, self.hidden_dim, num_layers=self.n_layers, batch_first=True)\n",
    "        #class예측을 출력\n",
    "        self.out=nn.Linear(self.hidden_dim,n_classes)\n",
    "    def _init_state(self, batch_size=1):\n",
    "        # 첫번째 은닉벡터 정의하는 함수\n",
    "        weight=next(self.parameters()).data #nn.GRU모듈의 첫번째 가중치텐서를 추출, self.parameters() 모델의 가중치정보를 반복하는 생성기매소드 (model.parameters())\n",
    "        return weight.new(self.n_layers, batch_size,self.hidden_dim).zero_()\n",
    "    def forward(self,x):\n",
    "        x=self.embed(x) \n",
    "        print(x.size, x.size(0))\n",
    "        h_0=self._init_state(batch_size=x.size(0))\n",
    "        x, _=self.gru(x,h_0) #batch_size, 입력 x의 길이, hidden_dim의 모양을 지닌 3d텐서\n",
    "        h_t=x[:,-1,:] # 시계열은닉벡터의 마지막 토큰들을 내포한 3d모양의 텐서를 추출 즉, 영화리뷰배열을 압축한 은닉벡터로 만든것\n",
    "        self.dropout(h_t) #드롭아웃과정 수행\n",
    "        logit=self.out(h_t) #출력\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (model,optimizer,train_iter):\n",
    "    model.train()\n",
    "    #enumerate는 반복마다 배치데이터를 반환한다.\n",
    "    # b 는 배치카운트\n",
    "    # batch는 batch_size만큼의 단어들 (문장)\n",
    "    for b,batch in enumerate(train_iter):\n",
    "        x,y=batch.text.to(device), batch.label.to(device)\n",
    "        # 2와 1을 가진 레이블데이터를 좀더 깔끔하게 하기위해 1과 0으로 변환\n",
    "        y.data.sub_(1) # y의 모든값에서 1씩 뺴줌\n",
    "        #매번 기울기를 새로계산하므로 기울기를 0으로 초기화\n",
    "        optimizer.zero_grad()\n",
    "        logit=model(x) #예측값 계산\n",
    "        loss=F.cross_entropy(logit,y)\n",
    "        loss.backward() #역전파수행\n",
    "        optimizer.step() # 가율가 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    \"\"\"evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    corrects, total_loss=0,0 \n",
    "    for batch in val_iter :\n",
    "        x,y=batch.text.to(device), batch.label.to(device)\n",
    "        y.data.sub(1) \n",
    "        logit=model(x)\n",
    "        loss=F.cross_entropy(logit,y,reduction='sum') # reduction=sum을 통해 오차의 합을 구함\n",
    "        total_loss=total_loss+loss.item #loss의 총합을 구함.\n",
    "        corrects=corrects+(logit.max(1)[1].view(y.size()).data==y.data.sum()) #모델이 맞힌 수를 저장.\n",
    "    size=len(val_iter.dataset)\n",
    "    avg_loss=total_loss/size\n",
    "    avg_acc=100.0*corrects/size\n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Basic GRU model...\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작전 모델객체를 정의\n",
    "# 모델내 은닉벡터의 차원값은 256, 임베딩된 토큰의 차원값은 128\n",
    "model=BasicGRU(1,256,vocab_size,128,n_classes,0.5).to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method size of Tensor object at 0x000002168D3FC900> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCEE8> 64\n",
      "<built-in method size of Tensor object at 0x00000216925165E8> 64\n",
      "<built-in method size of Tensor object at 0x0000021692516438> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168C393990> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x0000021692516438> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCEE8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x00000216925165E8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCB88> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x0000021692516438> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCEE8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x00000216925165E8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCB88> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x0000021692516438> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCEE8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x00000216925165E8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCB88> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x0000021692516438> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCEE8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x00000216925165E8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCB88> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x0000021692516438> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCEE8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x00000216925165E8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCB88> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x0000021692516438> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCEE8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x00000216925165E8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCB88> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x0000021692516438> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCEE8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x00000216925165E8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCB88> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x0000021692516438> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCEE8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x00000216925165E8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCB88> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x0000021692516438> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCEE8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x00000216925165E8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCB88> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x0000021692516438> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCEE8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x00000216925165E8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCB88> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x0000021692516438> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCEE8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x00000216925165E8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCB88> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x0000021692516438> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCEE8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x00000216925165E8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCB88> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x0000021692516438> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCEE8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x00000216925165E8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCB88> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x0000021692516438> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x000002168D3FCEE8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n",
      "<built-in method size of Tensor object at 0x00000216925165E8> 64\n",
      "<built-in method size of Tensor object at 0x000002168C4A4828> 64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-8710696cb2c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbest_val_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-fb9ff5b18151>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, train_iter)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mlogit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#예측값 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#역전파수행\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "for e in range(1, epochs+1):\n",
    "    train(model, optimizer, train_iter)\n",
    "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
    "\n",
    "    print(\"[이폭: %d] 검증 오차:%5.2f | 검증 정확도:%5.2f\" % (e, val_loss, val_accuracy))\n",
    "    \n",
    "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        if not os.path.isdir(\"snapshot\"):\n",
    "            os.makedirs(\"snapshot\")\n",
    "        torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "model.load_state_dict(torch.load('./snapshot/txtclassification.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iter)\n",
    "print('테스트 오차: %5.2f | 테스트 정확도: %5.2f' % (test_loss, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
