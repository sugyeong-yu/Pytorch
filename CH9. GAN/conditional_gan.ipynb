{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cGAN으로 생성 제어하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 100\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"Using Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion MNIST 데이터셋\n",
    "trainset = datasets.FashionMNIST(\n",
    "    './.data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "       transforms.ToTensor(),\n",
    "       transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = trainset,\n",
    "    batch_size  = BATCH_SIZE,\n",
    "    shuffle     = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자 (Generator)\n",
    "# 생성자는 무작위로 생성한 레이블 정보를 받아 해당 레이블에 대한 이미지를 생성하도록 학습한다.\n",
    "# 질문 : 이미지 변환은 어디서????? 그냥 레이블이랑 합쳐만 주는거아님?\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(10, 10)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(110, 256), #100은 무작위텐서크기 10개는 레이블\n",
    "            nn.LeakyReLU(0.2, inplace=True), # gan.ipynb에서와는 달리 LeakyReLu를 사용한다.\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True), # inplace=True는 입력을 복사하지 않고 바로 조작한다는 뜻.\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, labels):\n",
    "        c = self.embed(labels)\n",
    "        x = torch.cat([z, c], 1) # 무작위 벡터와 클래스 레이블을 이어붙이고 생성자에 입력한다.\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별자 (Discriminator)\n",
    "# 판별자는 레이블정보를 입력받아 레이블이 주어졌을때 가짜인 확률과 진짜인 확률들을 추정한다.\n",
    "# 10개의\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(10, 10)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(794, 1024), # 784 + 10(레이블)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid() # 진짜와 가짜를 뜻하는 0과1사이 값을 반환한다.\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        c = self.embed(labels)\n",
    "        x = torch.cat([x, c], 1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스를 만들고 모델의 가중치를 지정한 장치로 보내기\n",
    "D = Discriminator().to(DEVICE)\n",
    "G = Generator().to(DEVICE)\n",
    "\n",
    "# 이진 교차 엔트로피 함수와\n",
    "# 생성자와 판별자를 최적화할 Adam 모듈\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(D.parameters(), lr =0.0002)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr =0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이폭 [0/300] d_loss:0.3160 g_loss: 6.8871 D(x):0.89 D(G(z)):0.04\n",
      "이폭 [1/300] d_loss:0.5910 g_loss: 3.9762 D(x):0.87 D(G(z)):0.19\n",
      "이폭 [2/300] d_loss:0.3091 g_loss: 4.8783 D(x):0.92 D(G(z)):0.08\n",
      "이폭 [3/300] d_loss:0.1595 g_loss: 4.3155 D(x):0.95 D(G(z)):0.06\n",
      "이폭 [4/300] d_loss:0.5849 g_loss: 3.0070 D(x):0.78 D(G(z)):0.13\n",
      "이폭 [5/300] d_loss:0.4532 g_loss: 3.0106 D(x):0.82 D(G(z)):0.10\n",
      "이폭 [6/300] d_loss:1.0214 g_loss: 2.8349 D(x):0.64 D(G(z)):0.09\n",
      "이폭 [7/300] d_loss:0.6247 g_loss: 2.1058 D(x):0.79 D(G(z)):0.20\n",
      "이폭 [8/300] d_loss:0.6507 g_loss: 1.7656 D(x):0.82 D(G(z)):0.27\n",
      "이폭 [9/300] d_loss:0.6669 g_loss: 1.7414 D(x):0.81 D(G(z)):0.25\n",
      "이폭 [10/300] d_loss:0.6982 g_loss: 2.1408 D(x):0.81 D(G(z)):0.26\n",
      "이폭 [11/300] d_loss:0.8622 g_loss: 1.8217 D(x):0.74 D(G(z)):0.25\n",
      "이폭 [12/300] d_loss:0.8173 g_loss: 2.0123 D(x):0.77 D(G(z)):0.26\n",
      "이폭 [13/300] d_loss:0.7775 g_loss: 1.7512 D(x):0.75 D(G(z)):0.28\n",
      "이폭 [14/300] d_loss:0.7232 g_loss: 1.5495 D(x):0.76 D(G(z)):0.27\n",
      "이폭 [15/300] d_loss:0.8877 g_loss: 1.4896 D(x):0.69 D(G(z)):0.27\n",
      "이폭 [16/300] d_loss:0.7954 g_loss: 2.0424 D(x):0.69 D(G(z)):0.21\n",
      "이폭 [17/300] d_loss:0.7658 g_loss: 1.6869 D(x):0.74 D(G(z)):0.25\n",
      "이폭 [18/300] d_loss:0.9213 g_loss: 1.4370 D(x):0.69 D(G(z)):0.29\n",
      "이폭 [19/300] d_loss:0.8899 g_loss: 1.3454 D(x):0.73 D(G(z)):0.35\n",
      "이폭 [20/300] d_loss:1.1175 g_loss: 1.2468 D(x):0.58 D(G(z)):0.33\n",
      "이폭 [21/300] d_loss:0.8845 g_loss: 1.4447 D(x):0.73 D(G(z)):0.32\n",
      "이폭 [22/300] d_loss:1.0204 g_loss: 1.1669 D(x):0.63 D(G(z)):0.32\n",
      "이폭 [23/300] d_loss:1.2346 g_loss: 1.2664 D(x):0.63 D(G(z)):0.40\n",
      "이폭 [24/300] d_loss:1.0757 g_loss: 1.5536 D(x):0.62 D(G(z)):0.30\n",
      "이폭 [25/300] d_loss:0.8524 g_loss: 1.7157 D(x):0.66 D(G(z)):0.26\n",
      "이폭 [26/300] d_loss:1.0937 g_loss: 1.1672 D(x):0.64 D(G(z)):0.37\n",
      "이폭 [27/300] d_loss:0.9598 g_loss: 1.2177 D(x):0.67 D(G(z)):0.36\n",
      "이폭 [28/300] d_loss:0.9920 g_loss: 1.1852 D(x):0.66 D(G(z)):0.34\n",
      "이폭 [29/300] d_loss:1.0648 g_loss: 1.2556 D(x):0.67 D(G(z)):0.37\n",
      "이폭 [30/300] d_loss:1.1545 g_loss: 1.5034 D(x):0.56 D(G(z)):0.28\n",
      "이폭 [31/300] d_loss:1.2270 g_loss: 1.1542 D(x):0.58 D(G(z)):0.39\n",
      "이폭 [32/300] d_loss:1.1263 g_loss: 1.3266 D(x):0.65 D(G(z)):0.36\n",
      "이폭 [33/300] d_loss:1.1248 g_loss: 1.1094 D(x):0.62 D(G(z)):0.38\n",
      "이폭 [34/300] d_loss:1.1967 g_loss: 1.2937 D(x):0.56 D(G(z)):0.35\n",
      "이폭 [35/300] d_loss:1.1043 g_loss: 1.3641 D(x):0.60 D(G(z)):0.34\n",
      "이폭 [36/300] d_loss:0.8997 g_loss: 1.5824 D(x):0.68 D(G(z)):0.29\n",
      "이폭 [37/300] d_loss:1.1376 g_loss: 1.1206 D(x):0.59 D(G(z)):0.39\n",
      "이폭 [38/300] d_loss:1.3034 g_loss: 1.3584 D(x):0.63 D(G(z)):0.39\n",
      "이폭 [39/300] d_loss:0.9956 g_loss: 1.3172 D(x):0.68 D(G(z)):0.34\n",
      "이폭 [40/300] d_loss:0.9860 g_loss: 1.2805 D(x):0.67 D(G(z)):0.35\n",
      "이폭 [41/300] d_loss:1.0009 g_loss: 1.2975 D(x):0.69 D(G(z)):0.35\n",
      "이폭 [42/300] d_loss:1.1486 g_loss: 1.2332 D(x):0.58 D(G(z)):0.35\n",
      "이폭 [43/300] d_loss:1.0234 g_loss: 1.2544 D(x):0.66 D(G(z)):0.35\n",
      "이폭 [44/300] d_loss:1.1792 g_loss: 1.0267 D(x):0.59 D(G(z)):0.41\n",
      "이폭 [45/300] d_loss:1.0645 g_loss: 1.5280 D(x):0.70 D(G(z)):0.37\n",
      "이폭 [46/300] d_loss:1.1528 g_loss: 1.2533 D(x):0.58 D(G(z)):0.33\n",
      "이폭 [47/300] d_loss:1.1689 g_loss: 1.1853 D(x):0.59 D(G(z)):0.36\n",
      "이폭 [48/300] d_loss:0.9911 g_loss: 1.1729 D(x):0.64 D(G(z)):0.35\n",
      "이폭 [49/300] d_loss:1.2479 g_loss: 1.1463 D(x):0.59 D(G(z)):0.39\n",
      "이폭 [50/300] d_loss:1.0531 g_loss: 1.4914 D(x):0.69 D(G(z)):0.33\n",
      "이폭 [51/300] d_loss:1.2084 g_loss: 1.3741 D(x):0.60 D(G(z)):0.35\n",
      "이폭 [52/300] d_loss:1.1491 g_loss: 0.9025 D(x):0.60 D(G(z)):0.42\n",
      "이폭 [53/300] d_loss:1.1795 g_loss: 1.0152 D(x):0.63 D(G(z)):0.42\n",
      "이폭 [54/300] d_loss:1.2368 g_loss: 0.9881 D(x):0.59 D(G(z)):0.43\n",
      "이폭 [55/300] d_loss:1.1144 g_loss: 1.0084 D(x):0.61 D(G(z)):0.41\n",
      "이폭 [56/300] d_loss:0.9742 g_loss: 1.3360 D(x):0.62 D(G(z)):0.30\n",
      "이폭 [57/300] d_loss:1.1111 g_loss: 1.2013 D(x):0.62 D(G(z)):0.37\n",
      "이폭 [58/300] d_loss:1.1293 g_loss: 0.9425 D(x):0.61 D(G(z)):0.42\n",
      "이폭 [59/300] d_loss:1.1115 g_loss: 1.0971 D(x):0.64 D(G(z)):0.40\n",
      "이폭 [60/300] d_loss:1.1711 g_loss: 0.8514 D(x):0.64 D(G(z)):0.46\n",
      "이폭 [61/300] d_loss:1.2574 g_loss: 1.1688 D(x):0.53 D(G(z)):0.35\n",
      "이폭 [62/300] d_loss:1.1047 g_loss: 1.1473 D(x):0.62 D(G(z)):0.37\n",
      "이폭 [63/300] d_loss:1.1258 g_loss: 1.2802 D(x):0.62 D(G(z)):0.35\n",
      "이폭 [64/300] d_loss:1.1038 g_loss: 1.1615 D(x):0.70 D(G(z)):0.40\n",
      "이폭 [65/300] d_loss:1.1447 g_loss: 1.1335 D(x):0.58 D(G(z)):0.34\n",
      "이폭 [66/300] d_loss:1.2183 g_loss: 0.9577 D(x):0.60 D(G(z)):0.43\n",
      "이폭 [67/300] d_loss:1.0147 g_loss: 1.1334 D(x):0.67 D(G(z)):0.38\n",
      "이폭 [68/300] d_loss:0.9647 g_loss: 1.4295 D(x):0.69 D(G(z)):0.31\n",
      "이폭 [69/300] d_loss:1.1435 g_loss: 1.2024 D(x):0.64 D(G(z)):0.40\n",
      "이폭 [70/300] d_loss:1.1723 g_loss: 0.9909 D(x):0.61 D(G(z)):0.42\n",
      "이폭 [71/300] d_loss:1.2682 g_loss: 1.0710 D(x):0.58 D(G(z)):0.41\n",
      "이폭 [72/300] d_loss:1.1716 g_loss: 1.0253 D(x):0.56 D(G(z)):0.39\n",
      "이폭 [73/300] d_loss:1.2004 g_loss: 1.0096 D(x):0.55 D(G(z)):0.41\n",
      "이폭 [74/300] d_loss:1.0970 g_loss: 1.2437 D(x):0.66 D(G(z)):0.37\n",
      "이폭 [75/300] d_loss:1.0555 g_loss: 1.1143 D(x):0.64 D(G(z)):0.37\n",
      "이폭 [76/300] d_loss:1.1444 g_loss: 1.1805 D(x):0.61 D(G(z)):0.38\n",
      "이폭 [77/300] d_loss:1.1058 g_loss: 1.0923 D(x):0.61 D(G(z)):0.39\n",
      "이폭 [78/300] d_loss:1.1779 g_loss: 1.0541 D(x):0.63 D(G(z)):0.43\n",
      "이폭 [79/300] d_loss:1.2472 g_loss: 1.1688 D(x):0.63 D(G(z)):0.42\n",
      "이폭 [80/300] d_loss:1.2288 g_loss: 1.0327 D(x):0.58 D(G(z)):0.41\n",
      "이폭 [81/300] d_loss:0.9920 g_loss: 1.1429 D(x):0.63 D(G(z)):0.36\n",
      "이폭 [82/300] d_loss:1.0643 g_loss: 1.1235 D(x):0.66 D(G(z)):0.39\n",
      "이폭 [83/300] d_loss:1.1819 g_loss: 1.0258 D(x):0.61 D(G(z)):0.42\n",
      "이폭 [84/300] d_loss:1.1638 g_loss: 1.1043 D(x):0.60 D(G(z)):0.39\n",
      "이폭 [85/300] d_loss:1.0785 g_loss: 1.1045 D(x):0.62 D(G(z)):0.37\n",
      "이폭 [86/300] d_loss:1.2417 g_loss: 0.8960 D(x):0.58 D(G(z)):0.45\n",
      "이폭 [87/300] d_loss:1.1268 g_loss: 1.2213 D(x):0.60 D(G(z)):0.37\n",
      "이폭 [88/300] d_loss:1.2939 g_loss: 1.0583 D(x):0.58 D(G(z)):0.42\n",
      "이폭 [89/300] d_loss:1.1326 g_loss: 1.1059 D(x):0.62 D(G(z)):0.38\n",
      "이폭 [90/300] d_loss:1.3805 g_loss: 1.1491 D(x):0.48 D(G(z)):0.40\n",
      "이폭 [91/300] d_loss:1.2216 g_loss: 1.2522 D(x):0.58 D(G(z)):0.34\n",
      "이폭 [92/300] d_loss:1.2549 g_loss: 1.0024 D(x):0.65 D(G(z)):0.46\n",
      "이폭 [93/300] d_loss:1.2608 g_loss: 0.9609 D(x):0.56 D(G(z)):0.43\n",
      "이폭 [94/300] d_loss:1.1010 g_loss: 1.0334 D(x):0.63 D(G(z)):0.40\n",
      "이폭 [95/300] d_loss:1.1408 g_loss: 1.1788 D(x):0.59 D(G(z)):0.37\n",
      "이폭 [96/300] d_loss:1.0771 g_loss: 1.1025 D(x):0.63 D(G(z)):0.38\n",
      "이폭 [97/300] d_loss:1.2462 g_loss: 1.0300 D(x):0.59 D(G(z)):0.43\n",
      "이폭 [98/300] d_loss:1.3169 g_loss: 1.3007 D(x):0.57 D(G(z)):0.37\n",
      "이폭 [99/300] d_loss:1.0622 g_loss: 1.1779 D(x):0.61 D(G(z)):0.36\n",
      "이폭 [100/300] d_loss:1.1634 g_loss: 1.0386 D(x):0.58 D(G(z)):0.38\n",
      "이폭 [101/300] d_loss:1.2804 g_loss: 1.0972 D(x):0.55 D(G(z)):0.38\n",
      "이폭 [102/300] d_loss:1.3521 g_loss: 0.9992 D(x):0.53 D(G(z)):0.43\n",
      "이폭 [103/300] d_loss:1.0172 g_loss: 1.1565 D(x):0.67 D(G(z)):0.38\n",
      "이폭 [104/300] d_loss:1.0991 g_loss: 1.1267 D(x):0.61 D(G(z)):0.37\n",
      "이폭 [105/300] d_loss:1.1062 g_loss: 0.9505 D(x):0.62 D(G(z)):0.42\n",
      "이폭 [106/300] d_loss:1.0160 g_loss: 1.2985 D(x):0.65 D(G(z)):0.36\n",
      "이폭 [107/300] d_loss:1.1161 g_loss: 1.2177 D(x):0.59 D(G(z)):0.32\n",
      "이폭 [108/300] d_loss:1.1991 g_loss: 1.1204 D(x):0.57 D(G(z)):0.37\n",
      "이폭 [109/300] d_loss:1.2836 g_loss: 1.0011 D(x):0.58 D(G(z)):0.44\n",
      "이폭 [110/300] d_loss:1.1443 g_loss: 0.9716 D(x):0.63 D(G(z)):0.43\n",
      "이폭 [111/300] d_loss:1.2482 g_loss: 0.9895 D(x):0.55 D(G(z)):0.40\n",
      "이폭 [112/300] d_loss:1.0871 g_loss: 0.9745 D(x):0.62 D(G(z)):0.40\n",
      "이폭 [113/300] d_loss:1.2977 g_loss: 0.9649 D(x):0.57 D(G(z)):0.45\n",
      "이폭 [114/300] d_loss:1.2286 g_loss: 1.0941 D(x):0.63 D(G(z)):0.42\n",
      "이폭 [115/300] d_loss:1.2376 g_loss: 1.1070 D(x):0.57 D(G(z)):0.38\n",
      "이폭 [116/300] d_loss:1.1855 g_loss: 0.8995 D(x):0.60 D(G(z)):0.43\n",
      "이폭 [117/300] d_loss:1.0689 g_loss: 1.3804 D(x):0.63 D(G(z)):0.36\n",
      "이폭 [118/300] d_loss:1.1096 g_loss: 1.0656 D(x):0.63 D(G(z)):0.38\n",
      "이폭 [119/300] d_loss:1.2109 g_loss: 0.9245 D(x):0.57 D(G(z)):0.41\n",
      "이폭 [120/300] d_loss:1.0274 g_loss: 1.1375 D(x):0.63 D(G(z)):0.37\n",
      "이폭 [121/300] d_loss:1.1511 g_loss: 1.1668 D(x):0.61 D(G(z)):0.36\n",
      "이폭 [122/300] d_loss:1.2541 g_loss: 1.1607 D(x):0.54 D(G(z)):0.39\n",
      "이폭 [123/300] d_loss:1.2176 g_loss: 1.1589 D(x):0.58 D(G(z)):0.37\n",
      "이폭 [124/300] d_loss:1.2434 g_loss: 1.0104 D(x):0.60 D(G(z)):0.42\n",
      "이폭 [125/300] d_loss:1.2500 g_loss: 0.9446 D(x):0.57 D(G(z)):0.44\n",
      "이폭 [126/300] d_loss:1.1338 g_loss: 1.0269 D(x):0.59 D(G(z)):0.39\n",
      "이폭 [127/300] d_loss:1.3256 g_loss: 0.8861 D(x):0.55 D(G(z)):0.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이폭 [128/300] d_loss:1.1599 g_loss: 1.0357 D(x):0.60 D(G(z)):0.39\n",
      "이폭 [129/300] d_loss:1.2836 g_loss: 0.9070 D(x):0.55 D(G(z)):0.43\n",
      "이폭 [130/300] d_loss:1.3021 g_loss: 1.0356 D(x):0.58 D(G(z)):0.41\n",
      "이폭 [131/300] d_loss:1.0849 g_loss: 1.2057 D(x):0.59 D(G(z)):0.35\n",
      "이폭 [132/300] d_loss:1.1975 g_loss: 0.9894 D(x):0.54 D(G(z)):0.39\n",
      "이폭 [133/300] d_loss:1.2037 g_loss: 1.0071 D(x):0.56 D(G(z)):0.40\n",
      "이폭 [134/300] d_loss:1.3586 g_loss: 0.7803 D(x):0.55 D(G(z)):0.48\n",
      "이폭 [135/300] d_loss:1.0960 g_loss: 1.3504 D(x):0.56 D(G(z)):0.29\n",
      "이폭 [136/300] d_loss:1.2298 g_loss: 0.9643 D(x):0.62 D(G(z)):0.42\n",
      "이폭 [137/300] d_loss:1.1276 g_loss: 1.0070 D(x):0.62 D(G(z)):0.41\n",
      "이폭 [138/300] d_loss:1.0824 g_loss: 1.0769 D(x):0.63 D(G(z)):0.40\n",
      "이폭 [139/300] d_loss:1.0641 g_loss: 1.1952 D(x):0.64 D(G(z)):0.39\n",
      "이폭 [140/300] d_loss:1.3613 g_loss: 0.9529 D(x):0.52 D(G(z)):0.45\n",
      "이폭 [141/300] d_loss:1.2217 g_loss: 1.0125 D(x):0.62 D(G(z)):0.42\n",
      "이폭 [142/300] d_loss:1.2494 g_loss: 0.8275 D(x):0.58 D(G(z)):0.46\n",
      "이폭 [143/300] d_loss:1.1680 g_loss: 0.9340 D(x):0.64 D(G(z)):0.45\n",
      "이폭 [144/300] d_loss:1.2364 g_loss: 1.0078 D(x):0.60 D(G(z)):0.40\n",
      "이폭 [145/300] d_loss:1.2444 g_loss: 0.9622 D(x):0.54 D(G(z)):0.40\n",
      "이폭 [146/300] d_loss:1.3496 g_loss: 0.9978 D(x):0.51 D(G(z)):0.40\n",
      "이폭 [147/300] d_loss:1.3775 g_loss: 0.9300 D(x):0.52 D(G(z)):0.45\n",
      "이폭 [148/300] d_loss:1.1927 g_loss: 0.9561 D(x):0.59 D(G(z)):0.42\n",
      "이폭 [149/300] d_loss:1.2422 g_loss: 0.8285 D(x):0.57 D(G(z)):0.45\n",
      "이폭 [150/300] d_loss:1.3064 g_loss: 0.9320 D(x):0.59 D(G(z)):0.45\n",
      "이폭 [151/300] d_loss:1.2686 g_loss: 0.9476 D(x):0.59 D(G(z)):0.43\n",
      "이폭 [152/300] d_loss:1.2767 g_loss: 0.9308 D(x):0.57 D(G(z)):0.42\n",
      "이폭 [153/300] d_loss:1.3285 g_loss: 0.9270 D(x):0.53 D(G(z)):0.43\n",
      "이폭 [154/300] d_loss:1.2871 g_loss: 0.9036 D(x):0.53 D(G(z)):0.43\n",
      "이폭 [155/300] d_loss:1.1348 g_loss: 1.0673 D(x):0.59 D(G(z)):0.39\n",
      "이폭 [156/300] d_loss:1.2569 g_loss: 1.2044 D(x):0.55 D(G(z)):0.39\n",
      "이폭 [157/300] d_loss:1.1620 g_loss: 1.0272 D(x):0.60 D(G(z)):0.40\n",
      "이폭 [158/300] d_loss:1.2275 g_loss: 0.9917 D(x):0.57 D(G(z)):0.41\n",
      "이폭 [159/300] d_loss:1.2050 g_loss: 0.9738 D(x):0.56 D(G(z)):0.40\n",
      "이폭 [160/300] d_loss:1.1526 g_loss: 1.2333 D(x):0.60 D(G(z)):0.36\n",
      "이폭 [161/300] d_loss:1.2868 g_loss: 0.9614 D(x):0.59 D(G(z)):0.46\n",
      "이폭 [162/300] d_loss:1.3186 g_loss: 0.8249 D(x):0.59 D(G(z)):0.47\n",
      "이폭 [163/300] d_loss:1.3044 g_loss: 0.9417 D(x):0.53 D(G(z)):0.42\n",
      "이폭 [164/300] d_loss:1.1137 g_loss: 1.0092 D(x):0.61 D(G(z)):0.40\n",
      "이폭 [165/300] d_loss:1.2838 g_loss: 0.9069 D(x):0.60 D(G(z)):0.46\n",
      "이폭 [166/300] d_loss:1.2802 g_loss: 0.9738 D(x):0.58 D(G(z)):0.43\n",
      "이폭 [167/300] d_loss:1.2483 g_loss: 0.9931 D(x):0.54 D(G(z)):0.40\n",
      "이폭 [168/300] d_loss:1.0827 g_loss: 1.1990 D(x):0.59 D(G(z)):0.34\n",
      "이폭 [169/300] d_loss:1.2997 g_loss: 0.8047 D(x):0.57 D(G(z)):0.48\n",
      "이폭 [170/300] d_loss:1.1657 g_loss: 0.9691 D(x):0.62 D(G(z)):0.42\n",
      "이폭 [171/300] d_loss:1.2189 g_loss: 0.9322 D(x):0.58 D(G(z)):0.43\n",
      "이폭 [172/300] d_loss:1.3357 g_loss: 0.7715 D(x):0.55 D(G(z)):0.48\n",
      "이폭 [173/300] d_loss:1.2662 g_loss: 1.0085 D(x):0.54 D(G(z)):0.40\n",
      "이폭 [174/300] d_loss:1.1604 g_loss: 1.2816 D(x):0.59 D(G(z)):0.34\n",
      "이폭 [175/300] d_loss:1.3354 g_loss: 0.8050 D(x):0.58 D(G(z)):0.48\n",
      "이폭 [176/300] d_loss:1.2668 g_loss: 0.8402 D(x):0.56 D(G(z)):0.46\n",
      "이폭 [177/300] d_loss:1.1373 g_loss: 1.1312 D(x):0.60 D(G(z)):0.38\n",
      "이폭 [178/300] d_loss:1.3249 g_loss: 1.1571 D(x):0.53 D(G(z)):0.39\n",
      "이폭 [179/300] d_loss:1.2576 g_loss: 0.9544 D(x):0.54 D(G(z)):0.42\n",
      "이폭 [180/300] d_loss:1.0759 g_loss: 1.0976 D(x):0.62 D(G(z)):0.38\n",
      "이폭 [181/300] d_loss:1.1209 g_loss: 1.0663 D(x):0.60 D(G(z)):0.38\n",
      "이폭 [182/300] d_loss:1.1964 g_loss: 1.0737 D(x):0.62 D(G(z)):0.41\n",
      "이폭 [183/300] d_loss:1.2747 g_loss: 0.9663 D(x):0.57 D(G(z)):0.42\n",
      "이폭 [184/300] d_loss:1.2308 g_loss: 0.8984 D(x):0.58 D(G(z)):0.43\n",
      "이폭 [185/300] d_loss:1.2885 g_loss: 0.8884 D(x):0.57 D(G(z)):0.43\n",
      "이폭 [186/300] d_loss:1.2854 g_loss: 0.8067 D(x):0.57 D(G(z)):0.46\n",
      "이폭 [187/300] d_loss:1.1997 g_loss: 0.8304 D(x):0.55 D(G(z)):0.42\n",
      "이폭 [188/300] d_loss:1.1353 g_loss: 1.0545 D(x):0.59 D(G(z)):0.40\n",
      "이폭 [189/300] d_loss:1.2585 g_loss: 1.1410 D(x):0.60 D(G(z)):0.41\n",
      "이폭 [190/300] d_loss:1.2669 g_loss: 0.7520 D(x):0.58 D(G(z)):0.48\n",
      "이폭 [191/300] d_loss:1.3322 g_loss: 0.8776 D(x):0.55 D(G(z)):0.46\n",
      "이폭 [192/300] d_loss:1.1893 g_loss: 0.8112 D(x):0.61 D(G(z)):0.46\n",
      "이폭 [193/300] d_loss:1.1830 g_loss: 0.7791 D(x):0.61 D(G(z)):0.47\n",
      "이폭 [194/300] d_loss:1.3332 g_loss: 0.8339 D(x):0.51 D(G(z)):0.46\n",
      "이폭 [195/300] d_loss:1.2623 g_loss: 1.0741 D(x):0.54 D(G(z)):0.40\n",
      "이폭 [196/300] d_loss:1.1428 g_loss: 1.0090 D(x):0.62 D(G(z)):0.41\n",
      "이폭 [197/300] d_loss:1.3870 g_loss: 0.9004 D(x):0.52 D(G(z)):0.45\n",
      "이폭 [198/300] d_loss:1.3383 g_loss: 0.9571 D(x):0.52 D(G(z)):0.43\n",
      "이폭 [199/300] d_loss:1.3075 g_loss: 0.7501 D(x):0.56 D(G(z)):0.49\n",
      "이폭 [200/300] d_loss:1.2396 g_loss: 0.9617 D(x):0.62 D(G(z)):0.46\n",
      "이폭 [201/300] d_loss:1.3438 g_loss: 1.1092 D(x):0.52 D(G(z)):0.38\n",
      "이폭 [202/300] d_loss:1.2730 g_loss: 0.8511 D(x):0.57 D(G(z)):0.47\n",
      "이폭 [203/300] d_loss:1.1790 g_loss: 0.9788 D(x):0.59 D(G(z)):0.41\n",
      "이폭 [204/300] d_loss:1.2273 g_loss: 0.8437 D(x):0.58 D(G(z)):0.47\n",
      "이폭 [205/300] d_loss:1.2920 g_loss: 0.8673 D(x):0.55 D(G(z)):0.45\n",
      "이폭 [206/300] d_loss:1.2945 g_loss: 0.9297 D(x):0.60 D(G(z)):0.46\n",
      "이폭 [207/300] d_loss:1.2715 g_loss: 1.0305 D(x):0.65 D(G(z)):0.45\n",
      "이폭 [208/300] d_loss:1.3115 g_loss: 0.9542 D(x):0.55 D(G(z)):0.44\n",
      "이폭 [209/300] d_loss:1.3051 g_loss: 1.2393 D(x):0.55 D(G(z)):0.38\n",
      "이폭 [210/300] d_loss:1.1815 g_loss: 0.9364 D(x):0.59 D(G(z)):0.43\n",
      "이폭 [211/300] d_loss:1.2948 g_loss: 1.0206 D(x):0.54 D(G(z)):0.42\n",
      "이폭 [212/300] d_loss:1.1876 g_loss: 0.9778 D(x):0.63 D(G(z)):0.44\n",
      "이폭 [213/300] d_loss:1.2058 g_loss: 0.8672 D(x):0.59 D(G(z)):0.45\n",
      "이폭 [214/300] d_loss:1.4025 g_loss: 0.9284 D(x):0.52 D(G(z)):0.45\n",
      "이폭 [215/300] d_loss:1.2316 g_loss: 0.8712 D(x):0.60 D(G(z)):0.45\n",
      "이폭 [216/300] d_loss:1.3874 g_loss: 0.9454 D(x):0.52 D(G(z)):0.43\n",
      "이폭 [217/300] d_loss:1.1225 g_loss: 1.0231 D(x):0.59 D(G(z)):0.38\n",
      "이폭 [218/300] d_loss:1.2485 g_loss: 0.9867 D(x):0.56 D(G(z)):0.41\n",
      "이폭 [219/300] d_loss:1.2633 g_loss: 1.1601 D(x):0.55 D(G(z)):0.38\n",
      "이폭 [220/300] d_loss:1.4121 g_loss: 0.9077 D(x):0.50 D(G(z)):0.44\n",
      "이폭 [221/300] d_loss:1.3511 g_loss: 0.8124 D(x):0.54 D(G(z)):0.46\n",
      "이폭 [222/300] d_loss:1.2591 g_loss: 0.9181 D(x):0.57 D(G(z)):0.45\n",
      "이폭 [223/300] d_loss:1.2789 g_loss: 0.8000 D(x):0.58 D(G(z)):0.47\n",
      "이폭 [224/300] d_loss:1.3491 g_loss: 0.9742 D(x):0.52 D(G(z)):0.43\n",
      "이폭 [225/300] d_loss:1.2939 g_loss: 0.9227 D(x):0.55 D(G(z)):0.42\n",
      "이폭 [226/300] d_loss:1.2688 g_loss: 0.9572 D(x):0.54 D(G(z)):0.39\n",
      "이폭 [227/300] d_loss:1.1632 g_loss: 1.0091 D(x):0.58 D(G(z)):0.40\n",
      "이폭 [228/300] d_loss:1.1878 g_loss: 0.9685 D(x):0.62 D(G(z)):0.44\n",
      "이폭 [229/300] d_loss:1.1764 g_loss: 1.0931 D(x):0.60 D(G(z)):0.40\n",
      "이폭 [230/300] d_loss:1.1633 g_loss: 1.0254 D(x):0.63 D(G(z)):0.42\n",
      "이폭 [231/300] d_loss:1.3779 g_loss: 0.9117 D(x):0.53 D(G(z)):0.45\n",
      "이폭 [232/300] d_loss:1.3449 g_loss: 0.8536 D(x):0.57 D(G(z)):0.48\n",
      "이폭 [233/300] d_loss:1.3516 g_loss: 0.7557 D(x):0.54 D(G(z)):0.47\n",
      "이폭 [234/300] d_loss:1.3285 g_loss: 1.1418 D(x):0.56 D(G(z)):0.43\n",
      "이폭 [235/300] d_loss:1.3615 g_loss: 1.0132 D(x):0.56 D(G(z)):0.45\n",
      "이폭 [236/300] d_loss:1.3904 g_loss: 0.8201 D(x):0.51 D(G(z)):0.46\n",
      "이폭 [237/300] d_loss:1.3223 g_loss: 0.8283 D(x):0.54 D(G(z)):0.45\n",
      "이폭 [238/300] d_loss:1.2615 g_loss: 0.8339 D(x):0.57 D(G(z)):0.45\n",
      "이폭 [239/300] d_loss:1.2030 g_loss: 0.9740 D(x):0.59 D(G(z)):0.42\n",
      "이폭 [240/300] d_loss:1.1859 g_loss: 1.0911 D(x):0.61 D(G(z)):0.39\n",
      "이폭 [241/300] d_loss:1.2214 g_loss: 0.8406 D(x):0.59 D(G(z)):0.45\n",
      "이폭 [242/300] d_loss:1.2384 g_loss: 0.9231 D(x):0.56 D(G(z)):0.40\n",
      "이폭 [243/300] d_loss:1.1728 g_loss: 1.0237 D(x):0.58 D(G(z)):0.39\n",
      "이폭 [244/300] d_loss:1.2932 g_loss: 0.9684 D(x):0.58 D(G(z)):0.44\n",
      "이폭 [245/300] d_loss:1.0582 g_loss: 0.9457 D(x):0.69 D(G(z)):0.40\n",
      "이폭 [246/300] d_loss:1.3432 g_loss: 0.9335 D(x):0.56 D(G(z)):0.45\n",
      "이폭 [247/300] d_loss:1.2782 g_loss: 0.8679 D(x):0.52 D(G(z)):0.43\n",
      "이폭 [248/300] d_loss:1.2220 g_loss: 1.0346 D(x):0.53 D(G(z)):0.36\n",
      "이폭 [249/300] d_loss:1.2484 g_loss: 1.0295 D(x):0.58 D(G(z)):0.44\n",
      "이폭 [250/300] d_loss:1.2475 g_loss: 0.9172 D(x):0.54 D(G(z)):0.42\n",
      "이폭 [251/300] d_loss:1.3299 g_loss: 0.9635 D(x):0.54 D(G(z)):0.41\n",
      "이폭 [252/300] d_loss:1.2654 g_loss: 0.7947 D(x):0.58 D(G(z)):0.47\n",
      "이폭 [253/300] d_loss:1.2718 g_loss: 0.7681 D(x):0.56 D(G(z)):0.47\n",
      "이폭 [254/300] d_loss:1.2711 g_loss: 0.8470 D(x):0.57 D(G(z)):0.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이폭 [255/300] d_loss:1.3796 g_loss: 0.8272 D(x):0.57 D(G(z)):0.47\n",
      "이폭 [256/300] d_loss:1.3426 g_loss: 0.9632 D(x):0.52 D(G(z)):0.42\n",
      "이폭 [257/300] d_loss:1.2546 g_loss: 1.0157 D(x):0.57 D(G(z)):0.42\n",
      "이폭 [258/300] d_loss:1.2047 g_loss: 0.9986 D(x):0.62 D(G(z)):0.44\n",
      "이폭 [259/300] d_loss:1.3171 g_loss: 1.0010 D(x):0.54 D(G(z)):0.40\n",
      "이폭 [260/300] d_loss:1.3425 g_loss: 0.8781 D(x):0.55 D(G(z)):0.46\n",
      "이폭 [261/300] d_loss:1.2267 g_loss: 1.0366 D(x):0.62 D(G(z)):0.44\n",
      "이폭 [262/300] d_loss:1.1505 g_loss: 1.1203 D(x):0.61 D(G(z)):0.39\n",
      "이폭 [263/300] d_loss:1.2370 g_loss: 0.9579 D(x):0.57 D(G(z)):0.44\n",
      "이폭 [264/300] d_loss:1.1778 g_loss: 0.9074 D(x):0.58 D(G(z)):0.40\n",
      "이폭 [265/300] d_loss:1.3648 g_loss: 0.9658 D(x):0.53 D(G(z)):0.44\n",
      "이폭 [266/300] d_loss:1.2038 g_loss: 0.9570 D(x):0.57 D(G(z)):0.42\n",
      "이폭 [267/300] d_loss:1.2762 g_loss: 0.8381 D(x):0.58 D(G(z)):0.49\n",
      "이폭 [268/300] d_loss:1.0946 g_loss: 1.3682 D(x):0.65 D(G(z)):0.37\n",
      "이폭 [269/300] d_loss:1.5071 g_loss: 0.8394 D(x):0.51 D(G(z)):0.50\n",
      "이폭 [270/300] d_loss:1.1830 g_loss: 0.8900 D(x):0.59 D(G(z)):0.44\n",
      "이폭 [271/300] d_loss:1.2162 g_loss: 0.9783 D(x):0.61 D(G(z)):0.44\n",
      "이폭 [272/300] d_loss:1.2841 g_loss: 0.9193 D(x):0.57 D(G(z)):0.44\n",
      "이폭 [273/300] d_loss:1.3742 g_loss: 0.9791 D(x):0.53 D(G(z)):0.41\n",
      "이폭 [274/300] d_loss:1.1375 g_loss: 1.2430 D(x):0.62 D(G(z)):0.39\n",
      "이폭 [275/300] d_loss:1.1785 g_loss: 1.1205 D(x):0.61 D(G(z)):0.40\n",
      "이폭 [276/300] d_loss:1.4276 g_loss: 1.0428 D(x):0.51 D(G(z)):0.42\n",
      "이폭 [277/300] d_loss:1.3847 g_loss: 1.0324 D(x):0.55 D(G(z)):0.44\n",
      "이폭 [278/300] d_loss:1.1892 g_loss: 1.1183 D(x):0.62 D(G(z)):0.40\n",
      "이폭 [279/300] d_loss:1.2214 g_loss: 1.0615 D(x):0.56 D(G(z)):0.38\n",
      "이폭 [280/300] d_loss:1.2796 g_loss: 1.0563 D(x):0.54 D(G(z)):0.39\n",
      "이폭 [281/300] d_loss:1.1867 g_loss: 0.8633 D(x):0.63 D(G(z)):0.45\n",
      "이폭 [282/300] d_loss:1.1535 g_loss: 1.0292 D(x):0.59 D(G(z)):0.40\n",
      "이폭 [283/300] d_loss:1.2170 g_loss: 0.9809 D(x):0.58 D(G(z)):0.42\n",
      "이폭 [284/300] d_loss:1.2118 g_loss: 0.9556 D(x):0.60 D(G(z)):0.44\n",
      "이폭 [285/300] d_loss:1.2876 g_loss: 1.0758 D(x):0.53 D(G(z)):0.40\n",
      "이폭 [286/300] d_loss:1.4553 g_loss: 0.9380 D(x):0.54 D(G(z)):0.46\n",
      "이폭 [287/300] d_loss:1.3330 g_loss: 0.8979 D(x):0.53 D(G(z)):0.44\n",
      "이폭 [288/300] d_loss:1.3713 g_loss: 0.8559 D(x):0.50 D(G(z)):0.44\n",
      "이폭 [289/300] d_loss:1.3561 g_loss: 0.8846 D(x):0.54 D(G(z)):0.46\n",
      "이폭 [290/300] d_loss:1.2901 g_loss: 0.9300 D(x):0.53 D(G(z)):0.42\n",
      "이폭 [291/300] d_loss:1.3586 g_loss: 1.0188 D(x):0.53 D(G(z)):0.41\n",
      "이폭 [292/300] d_loss:1.2751 g_loss: 0.8963 D(x):0.57 D(G(z)):0.44\n",
      "이폭 [293/300] d_loss:1.1592 g_loss: 1.0320 D(x):0.64 D(G(z)):0.43\n",
      "이폭 [294/300] d_loss:1.2472 g_loss: 0.8309 D(x):0.61 D(G(z)):0.47\n",
      "이폭 [295/300] d_loss:1.2423 g_loss: 1.0166 D(x):0.63 D(G(z)):0.43\n",
      "이폭 [296/300] d_loss:1.3765 g_loss: 0.9225 D(x):0.49 D(G(z)):0.44\n",
      "이폭 [297/300] d_loss:1.2616 g_loss: 0.8626 D(x):0.56 D(G(z)):0.45\n",
      "이폭 [298/300] d_loss:1.2170 g_loss: 0.8461 D(x):0.57 D(G(z)):0.43\n",
      "이폭 [299/300] d_loss:1.1471 g_loss: 1.2162 D(x):0.60 D(G(z)):0.38\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "#이번예제의 train+loader는 2번째 반환값도 사용할 것이므로 (images,labels)\n",
    "#그리고 일반 gan예제와 같이 진짜와 가짜 레이블을 만든다.\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(BATCH_SIZE, -1).to(DEVICE)\n",
    "        \n",
    "        # '진짜'와 '가짜' 레이블 생성\n",
    "        real_labels = torch.ones(BATCH_SIZE, 1).to(DEVICE)\n",
    "        fake_labels = torch.zeros(BATCH_SIZE, 1).to(DEVICE)\n",
    "\n",
    "        # 판별자가 진짜 이미지를 진짜로 인식하는 오차 계산 (데이터셋 레이블 입력)\n",
    "        labels = labels.to(DEVICE)\n",
    "        outputs = D(images, labels)# 이미지와 레이블을 같이 넘겨줌\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "    \n",
    "        # 무작위 텐서와 무작위 레이블을 생성자에 입력해 가짜 이미지 생성\n",
    "        z = torch.randn(BATCH_SIZE, 100).to(DEVICE)\n",
    "        g_label = torch.randint(0, 10, (BATCH_SIZE,)).to(DEVICE)\n",
    "        fake_images = G(z, g_label)\n",
    "        \n",
    "        # 판별자가 가짜 이미지를 가짜로 인식하는 오차 계산\n",
    "        outputs = D(fake_images, g_label)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # 진짜와 가짜 이미지를 갖고 낸 오차를 더해서 판별자의 오차 계산\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        \n",
    "        # 역전파 알고리즘으로 판별자 모델의 학습을 진행\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # 생성자가 판별자를 속였는지에 대한 오차 계산(무작위 레이블 입력)\n",
    "        fake_images = G(z, g_label)\n",
    "        outputs = D(fake_images, g_label)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "\n",
    "        # 역전파 알고리즘으로 생성자 모델의 학습을 진행\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "    print('이폭 [{}/{}] d_loss:{:.4f} g_loss: {:.4f} D(x):{:.2f} D(G(z)):{:.2f}'\n",
    "          .format(epoch,\n",
    "                  EPOCHS,\n",
    "                  d_loss.item(),\n",
    "                  g_loss.item(),\n",
    "                  real_score.mean().item(),\n",
    "                  fake_score.mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 만들고 싶은 아이템 생성하고 시각화하기 학습후!!!\n",
    "item_number = 9 # 아이템 번호\n",
    "z = torch.randn(1, 100).to(DEVICE) # 배치 크기 1\n",
    "g_label = torch.full((1,), item_number, dtype=torch.long).to(DEVICE) # full(size,value) > size만큼의 텐서를 value값으로 생성\n",
    "print(g_label)\n",
    "sample_images = G(z, g_label)\n",
    "\n",
    "sample_images_img = np.reshape(sample_images.data.cpu().numpy()\n",
    "                               [0],(28, 28))\n",
    "plt.imshow(sample_images_img, cmap = 'gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
